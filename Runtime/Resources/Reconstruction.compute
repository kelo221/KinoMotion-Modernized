// Kino/Motion - Motion blur reconstruction compute shader
// Async compute version for Unity 6 DX12/Vulkan
#pragma kernel CSReconstruction

// Note: We can't include Common.hlsl because it uses sampler2D types incompatible with compute shaders
// Instead, we declare what we need directly

// Input textures (set via SetGlobalTexture from Graphics Queue)
Texture2D<float4> _Source;
Texture2D<float4> _VelocityTex;
Texture2D<float2> _NeighborMaxTex;

// Output texture (must have enableRandomWrite = true)
RWTexture2D<float4> _Result;

// Samplers
SamplerState sampler_LinearClamp;
SamplerState sampler_PointClamp;

// Shader parameters (set from C#)
float _LoopCount;
float _MaxBlurRadius;
float _RcpMaxBlurRadius;

// Custom uniforms (BIRP does NOT auto-bind _ScreenParams/_Time to Compute Shaders!)
// These MUST be manually set from C# via SetComputeVectorParam
float4 _CustomScreenParams;  // (width, height, 1/width, 1/height)
float _CustomTime;           // Time.time for noise
float _ReversedZ;            // 1.0 if reversed-Z buffer, 0.0 otherwise

// Camera motion filtering uniforms
float _FilterCameraMotion;
float4x4 _InvVP;
float4x4 _PrevVP;
float4x4 _CameraInvProj;
float4 _ZBufferParams;       // For LinearEyeDepth calculation

// Depth texture for camera motion filtering
Texture2D<float> _CameraDepthTexture;

// LinearEyeDepth for compute shader (since we can't include UnityCG.cginc)
float LinearEyeDepth(float z)
{
    return 1.0 / (_ZBufferParams.z * z + _ZBufferParams.w);
}

// Constants
#define UNITY_PI 3.14159265359

// Reconstruction logic (adapted from Reconstruction.hlsl)
float Interval(float phase, float interval)
{
    return frac(phase / interval) > 0.499;
}

float GradientNoise(float2 uv)
{
    // Use custom uniforms (BIRP doesn't auto-bind _ScreenParams/_Time to Compute!)
    uv = floor((uv + _CustomTime) * _CustomScreenParams.xy);
    float f = dot(float2(0.06711056, 0.00583715), uv);
    return frac(52.9829189 * frac(f));
}

float2 JitterTile(float2 uv)
{
    float rx, ry;
    sincos(GradientNoise(uv + float2(2, 0)) * UNITY_PI * 2, ry, rx);
    float2 texelSize;
    _NeighborMaxTex.GetDimensions(texelSize.x, texelSize.y);
    return float2(rx, ry) / (texelSize * 4);
}

float3 SampleVelocity(float2 uv)
{
    // 1. Get the total velocity (Camera + Object) from packed texture
    float4 v = _VelocityTex.SampleLevel(sampler_PointClamp, uv, 0);
    float2 totalVelocity = (v.xy * 2 - 1) * _MaxBlurRadius;
    
    // 2. Filter out camera motion if enabled
    if (_FilterCameraMotion > 0.5)
    {
        // Sample raw depth and convert to linear eye depth
        float rawDepth = _CameraDepthTexture.SampleLevel(sampler_PointClamp, uv, 0);
        float linearDepth = LinearEyeDepth(rawDepth);
        
        // Reconstruct view-space position using inverse projection
        float2 ndc = uv * 2.0 - 1.0;
        float4 viewPos = mul(_CameraInvProj, float4(ndc, rawDepth, 1.0));
        viewPos.xyz /= viewPos.w;
        
        // Transform to world space using inverse view-projection
        float4 worldPos = mul(_InvVP, float4(ndc, rawDepth, 1.0));
        worldPos.xyz /= worldPos.w;
        
        // Project using previous frame's VP matrix
        float4 prevClipPos = mul(_PrevVP, worldPos);
        float2 prevNDC = prevClipPos.xy / prevClipPos.w;
        float2 prevUV = prevNDC * 0.5 + 0.5;
        
        // Camera-induced velocity in pixels
        float2 cameraVelocity = (uv - prevUV) * _CustomScreenParams.xy;
        totalVelocity -= cameraVelocity;
    }
    
    return float3(totalVelocity, v.z);
}

[numthreads(8, 8, 1)]
void CSReconstruction(uint3 id : SV_DispatchThreadID)
{
    // Get texture dimensions
    uint2 res;
    _Source.GetDimensions(res.x, res.y);
    
    // Early exit for out-of-bounds threads
    if (id.x >= res.x || id.y >= res.y)
        return;
    
    
    // Calculate UV coordinates
    float2 uv = (id.xy + 0.5) / float2(res);
    
    // Color sample at the center point
    float4 c_p = _Source.SampleLevel(sampler_LinearClamp, uv, 0);
    
    // Velocity/Depth sample at the center point
    float3 vd_p = SampleVelocity(uv);
    float l_v_p = max(length(vd_p.xy), 0.5);
    float rcp_d_p = 1.0 / vd_p.z;
    
    // NeighborMax vector sample at the center point
    float2 v_max = _NeighborMaxTex.SampleLevel(sampler_PointClamp, uv + JitterTile(uv), 0).xy;
    float l_v_max = length(v_max);
    float rcp_l_v_max = 1.0 / l_v_max;
    
    // Escape early if the NeighborMax vector is small enough
    if (l_v_max < 2)
    {
        _Result[id.xy] = c_p;
        return;
    }
    
    // Use V_p as a secondary sampling direction
    float2 v_alt = (l_v_p * 2 > l_v_max) ? vd_p.xy * (l_v_max / l_v_p) : v_max;
    
    // Determine the sample count
    float sc = floor(min(_LoopCount, l_v_max / 2));
    
    // Loop variables
    float dt = 1.0 / sc;
    float t_offs = (GradientNoise(uv) - 0.5) * dt;
    float t = 1.0 - dt / 2;
    float count = 0;
    
    // Background velocity
    float l_v_bg = max(l_v_p, 1);
    
    // Color accumulation
    float4 acc = 0;
    
    // Sampling loop
    [loop]
    while (t > dt / 4)
    {
        // Sampling direction (switched per every two samples)
        float2 v_s = Interval(count, 4) ? v_alt : v_max;
        
        // Sample position (inverted per every sample)
        float t_s = (Interval(count, 2) ? -t : t) + t_offs;
        
        // Distance to the sample position
        float l_t = l_v_max * abs(t_s);
        
        // UVs for the sample position
        float2 uv0 = uv + v_s * t_s / float2(res);
        float2 uv1 = uv + v_s * t_s / float2(res);
        
        // Color sample
        float3 c = _Source.SampleLevel(sampler_LinearClamp, uv0, 0).rgb;
        
        // Velocity/Depth sample
        float3 vd = SampleVelocity(uv1);
        
        // Background/Foreground separation (handle reversed-Z via runtime uniform)
        float fg = (_ReversedZ > 0.5) 
            ? saturate((vd.z - vd_p.z) * 20 * rcp_d_p)
            : saturate((vd_p.z - vd.z) * 20 * rcp_d_p);
        
        // Length of the velocity vector
        float l_v = lerp(l_v_bg, length(vd.xy), fg);
        
        // Sample weight
        float w = saturate(l_v - l_t) / l_v * (1.2 - t);
        
        // Color accumulation
        acc += float4(c, 1) * w;
        
        // Update the background velocity
        l_v_bg = max(l_v_bg, l_v);
        
        // Advance to the next sample
        t = Interval(count, 2) ? t - dt : t;
        count += 1;
    }
    
    // Add the center sample
    acc += float4(c_p.rgb, 1) * (1.2 / (l_v_bg * sc * 2));
    
    // Write result
    _Result[id.xy] = float4(acc.rgb / acc.a, c_p.a);
}
